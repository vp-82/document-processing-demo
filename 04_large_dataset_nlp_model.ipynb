{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966c7aaf-4d1a-401b-a25b-2bac0bb40d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: sudo apt-get update\n",
      "Command output: Get:1 https://deb.nodesource.com/node_16.x focal InRelease [4583 B]\n",
      "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:3 https://deb.nodesource.com/node_16.x focal/main amd64 Packages [776 B]\n",
      "Get:4 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1047 kB]\n",
      "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2675 kB]\n",
      "Get:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2203 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [28.5 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3157 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [31.2 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1342 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2341 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Fetched 26.4 MB in 3s (7999 kB/s)\n",
      "Reading package lists...\n",
      "\n",
      "Running command: sudo apt-get install software-properties-common -y\n",
      "Command output: Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  python3-software-properties\n",
      "Recommended packages:\n",
      "  unattended-upgrades\n",
      "The following packages will be upgraded:\n",
      "  python3-software-properties software-properties-common\n",
      "2 upgraded, 0 newly installed, 0 to remove and 138 not upgraded.\n",
      "Need to get 32.0 kB of archives.\n",
      "After this operation, 18.4 kB disk space will be freed.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 software-properties-common all 0.99.9.11 [10.4 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-software-properties all 0.99.9.11 [21.6 kB]\n",
      "Fetched 32.0 kB in 0s (118 kB/s)\n",
      "(Reading database ... 78556 files and directories currently installed.)\n",
      "Preparing to unpack .../software-properties-common_0.99.9.11_all.deb ...\n",
      "Unpacking software-properties-common (0.99.9.11) over (0.99.9.8) ...\n",
      "Preparing to unpack .../python3-software-properties_0.99.9.11_all.deb ...\n",
      "Unpacking python3-software-properties (0.99.9.11) over (0.99.9.8) ...\n",
      "Setting up python3-software-properties (0.99.9.11) ...\n",
      "Setting up software-properties-common (0.99.9.11) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for dbus (1.12.16-2ubuntu2.2) ...\n",
      "\n",
      "Running command: sudo add-apt-repository ppa:alex-p/tesseract-ocr -y\n",
      "Command output: Hit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:2 https://deb.nodesource.com/node_16.x focal InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Get:5 http://ppa.launchpad.net/alex-p/tesseract-ocr/ubuntu focal InRelease [17.6 kB]\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Get:8 http://ppa.launchpad.net/alex-p/tesseract-ocr/ubuntu focal/main amd64 Packages [2130 B]\n",
      "Fetched 19.7 kB in 1s (27.6 kB/s)\n",
      "Reading package lists...\n",
      "\n",
      "Running command: sudo apt-get update\n",
      "Command output: Hit:1 https://deb.nodesource.com/node_16.x focal InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:3 http://ppa.launchpad.net/alex-p/tesseract-ocr/ubuntu focal InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Reading package lists...\n",
      "\n",
      "Running command: sudo apt-get install tesseract-ocr -y\n",
      "Command output: Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  libarchive13 liblept5 libtesseract4 tesseract-ocr-eng tesseract-ocr-osd\n",
      "Suggested packages:\n",
      "  lrzip\n",
      "The following NEW packages will be installed:\n",
      "  libarchive13 liblept5 libtesseract4 tesseract-ocr tesseract-ocr-eng\n",
      "  tesseract-ocr-osd\n",
      "0 upgraded, 6 newly installed, 0 to remove and 138 not upgraded.\n",
      "Need to get 7498 kB of archives.\n",
      "After this operation, 23.2 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libarchive13 amd64 3.4.0-2ubuntu1.2 [327 kB]\n",
      "Get:2 http://ppa.launchpad.net/alex-p/tesseract-ocr/ubuntu focal/main amd64 libtesseract4 amd64 4.1.3-1ppa1~focal1 [1264 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 liblept5 amd64 1.79.0-1 [999 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1598 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2990 kB]\n",
      "Get:6 http://ppa.launchpad.net/alex-p/tesseract-ocr/ubuntu focal/main amd64 tesseract-ocr amd64 4.1.3-1ppa1~focal1 [320 kB]\n",
      "Fetched 7498 kB in 2s (3592 kB/s)\n",
      "Selecting previously unselected package libarchive13:amd64.\n",
      "(Reading database ... 78553 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libarchive13_3.4.0-2ubuntu1.2_amd64.deb ...\n",
      "Unpacking libarchive13:amd64 (3.4.0-2ubuntu1.2) ...\n",
      "Selecting previously unselected package liblept5:amd64.\n",
      "Preparing to unpack .../1-liblept5_1.79.0-1_amd64.deb ...\n",
      "Unpacking liblept5:amd64 (1.79.0-1) ...\n",
      "Selecting previously unselected package libtesseract4:amd64.\n",
      "Preparing to unpack .../2-libtesseract4_4.1.3-1ppa1~focal1_amd64.deb ...\n",
      "Unpacking libtesseract4:amd64 (4.1.3-1ppa1~focal1) ...\n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "Preparing to unpack .../3-tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../4-tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../5-tesseract-ocr_4.1.3-1ppa1~focal1_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.1.3-1ppa1~focal1) ...\n",
      "Setting up libarchive13:amd64 (3.4.0-2ubuntu1.2) ...\n",
      "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n",
      "Setting up liblept5:amd64 (1.79.0-1) ...\n",
      "Setting up libtesseract4:amd64 (4.1.3-1ppa1~focal1) ...\n",
      "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n",
      "Setting up tesseract-ocr (4.1.3-1ppa1~focal1) ...\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Processing triggers for libc-bin (2.31-0ubuntu9.7) ...\n",
      "\n",
      "Installing pytesseract...\n",
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (21.3)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from pytesseract) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mpytesseract installed successfully.\n",
      "Installing pillow...\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (9.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mpillow installed successfully.\n",
      "Installing transformers...\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.20.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mtransformers installed successfully.\n",
      "Installing scikit-learn...\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.8.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mscikit-learn installed successfully.\n",
      "Installing pandas...\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.23.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mpandas installed successfully.\n",
      "Installing datasets...\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.4.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.23.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (18.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mdatasets installed successfully.\n",
      "Importing libraries...\n",
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "!python setup_04.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84952d15-fb2b-4d48-bdea-ebb84efd1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import os\n",
    "    import pytesseract\n",
    "    from PIL import Image\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    import pandas as pd\n",
    "    from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0a4ea2e-9431-4358-af27-58b3386ae8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration vaclavpechtor--rvl_cdip-small-200-853f638e95c0bf72\n",
      "Reusing dataset imagefolder (./dataset/rvl-cdip-small-200/hf_cache/vaclavpechtor___imagefolder/vaclavpechtor--rvl_cdip-small-200-853f638e95c0bf72/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597)\n",
      "Using custom data configuration vaclavpechtor--rvl_cdip-small-200-853f638e95c0bf72\n",
      "Reusing dataset imagefolder (./dataset/rvl-cdip-small-200/hf_cache/vaclavpechtor___imagefolder/vaclavpechtor--rvl_cdip-small-200-853f638e95c0bf72/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"vaclavpechtor/rvl_cdip-small-200\", split=\"train\", cache_dir=\"./dataset/rvl-cdip-small-200/hf_cache\")\n",
    "validation_dataset = load_dataset(\"vaclavpechtor/rvl_cdip-small-200\", split=\"validation\", cache_dir=\"./dataset/rvl-cdip-small-200/hf_cache\")\n",
    "\n",
    "ocr_dataset = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "507baa7b-e634-4dc2-99c7-216831766efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = ocr_dataset['train'].features['label'].names\n",
    "label_to_id = {label: i for i, label in enumerate(class_labels)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0782f8e0-41ca-4f26-9e22-759fd9c5e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_dataset(dataset, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7444841-8aa0-409f-875b-f6e631e51144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb8f9c8-c809-43e6-aca8-44b289c0cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_image(img):\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2cbb16-1995-444e-a358-aad7fb21f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from pkl...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('./dataset/rvl-cdip-small-200/ocr_dataset.pkl'):\n",
    "    print('Loading dataset from pkl...')\n",
    "    ocr_dataset = load_dataset('./dataset/rvl-cdip-small-200/ocr_dataset.pkl')\n",
    "else:\n",
    "    print('Running OCR...')\n",
    "    ocr_dataset = ocr_dataset.map(lambda x: {\"text\": ocr_image(x[\"image\"])})\n",
    "    ocr_dataset = ocr_dataset.map(lambda example: {'label': label_to_id[example['label']] if isinstance(example['label'], str) else example['label']})\n",
    "    save_dataset(ocr_dataset, './dataset/rvl-cdip-small-200/ocr_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e0052f-f775-459e-81e5-e3c25874da62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label', 'text'],\n",
       "        num_rows: 2560\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'label', 'text'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "209d178c-d11f-4f45-afd2-26bc90736e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_dataset.set_format(type='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27303209-a034-4c11-b744-f8298475edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ocr_dataset['train'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adc0ccec-6c29-4d98-8c99-dca488969491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\na\\n\\nCevetrom Phi\"eMonis,\\n\\n” Saratoe\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>eae Arizona\\nFebruary 20-21, 1984 oo\\n\\nSit 00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>ae\\nPRIVEE SITET\\neae beaters\\n\\n \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>a\\nholds backtar;\\nf ut lets Ue Sul.\\nmenthol ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>fl .\\na\\n\\n \\n\\n \\n\\nyou should know that many...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label  \\\n",
       "0  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "1  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "2  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "3  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "4  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "\n",
       "                                                text  \n",
       "0   \\n\\na\\n\\nCevetrom Phi\"eMonis,\\n\\n” Saratoe\\n\\...  \n",
       "1  eae Arizona\\nFebruary 20-21, 1984 oo\\n\\nSit 00...  \n",
       "2              ae\\nPRIVEE SITET\\neae beaters\\n\\n \\n\n",
       "  \n",
       "3  a\\nholds backtar;\\nf ut lets Ue Sul.\\nmenthol ...  \n",
       "4  fl .\\na\\n\\n \\n\\n \\n\\nyou should know that many...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b7e84dd-dfb6-4463-83cc-116e5b4f4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category_name'] = df['label'].map(id_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6576de9a-c135-4213-8803-e48fb97787c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\na\\n\\nCevetrom Phi\"eMonis,\\n\\n” Saratoe\\n\\...</td>\n",
       "      <td>advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>eae Arizona\\nFebruary 20-21, 1984 oo\\n\\nSit 00...</td>\n",
       "      <td>advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>ae\\nPRIVEE SITET\\neae beaters\\n\\n \\n</td>\n",
       "      <td>advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>a\\nholds backtar;\\nf ut lets Ue Sul.\\nmenthol ...</td>\n",
       "      <td>advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.TiffImagePlugin.TiffImageFile image mode=...</td>\n",
       "      <td>0</td>\n",
       "      <td>fl .\\na\\n\\n \\n\\n \\n\\nyou should know that many...</td>\n",
       "      <td>advertisement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label  \\\n",
       "0  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "1  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "2  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "3  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "4  <PIL.TiffImagePlugin.TiffImageFile image mode=...      0   \n",
       "\n",
       "                                                text  category_name  \n",
       "0   \\n\\na\\n\\nCevetrom Phi\"eMonis,\\n\\n” Saratoe\\n\\...  advertisement  \n",
       "1  eae Arizona\\nFebruary 20-21, 1984 oo\\n\\nSit 00...  advertisement  \n",
       "2              ae\\nPRIVEE SITET\\neae beaters\\n\\n \\n\n",
       "  advertisement  \n",
       "3  a\\nholds backtar;\\nf ut lets Ue Sul.\\nmenthol ...  advertisement  \n",
       "4  fl .\\na\\n\\n \\n\\n \\n\\nyou should know that many...  advertisement  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dee9fe1-8e2d-494e-94af-411e13d607de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_dataset.set_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050eab3e-5437-47fe-ac2c-fa12be4baf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a263fec81246ae95bd7ceadc7c74cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd26181b987d4312992bc9060f2685c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97a0f139102414f87abce7b1b0253ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0516debfc3a4a2fa4a1726cc112a915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3ccdb217734e81b04562220c73dc18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=len(label_to_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e44b2d8-ce9a-4b4d-bb7b-fb1503ec148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b64afa7f-1166-4b01-a0e5-ee58e222fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at ./dataset/rvl-cdip-small-200/hf_cache/vaclavpechtor___imagefolder/vaclavpechtor--rvl_cdip-small-200-853f638e95c0bf72/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597/cache-1c80317fa3b1799d.arrow\n",
      "Loading cached processed dataset at ./dataset/rvl-cdip-small-200/hf_cache/vaclavpechtor___imagefolder/vaclavpechtor--rvl_cdip-small-200-853f638e95c0bf72/0.0.0/48efdc62d40223daee675ca093d163bcb6cb0b7d7f93eb25aebf5edca72dc597/cache-bdd640fb06671ad1.arrow\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2560\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 02:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.367627</td>\n",
       "      <td>0.654687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>1.549862</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>1.660206</td>\n",
       "      <td>0.653125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229600</td>\n",
       "      <td>1.646754</td>\n",
       "      <td>0.670312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>1.721966</td>\n",
       "      <td>0.665625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.136500</td>\n",
       "      <td>1.891162</td>\n",
       "      <td>0.662500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109200</td>\n",
       "      <td>1.871702</td>\n",
       "      <td>0.664062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>1.886006</td>\n",
       "      <td>0.665625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>1.875578</td>\n",
       "      <td>0.673438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>1.874407</td>\n",
       "      <td>0.668750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-320\n",
      "Configuration saved in output/checkpoint-320/config.json\n",
      "Model weights saved in output/checkpoint-320/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-640\n",
      "Configuration saved in output/checkpoint-640/config.json\n",
      "Model weights saved in output/checkpoint-640/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-960\n",
      "Configuration saved in output/checkpoint-960/config.json\n",
      "Model weights saved in output/checkpoint-960/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1280\n",
      "Configuration saved in output/checkpoint-1280/config.json\n",
      "Model weights saved in output/checkpoint-1280/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1600\n",
      "Configuration saved in output/checkpoint-1600/config.json\n",
      "Model weights saved in output/checkpoint-1600/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-1920\n",
      "Configuration saved in output/checkpoint-1920/config.json\n",
      "Model weights saved in output/checkpoint-1920/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2240\n",
      "Configuration saved in output/checkpoint-2240/config.json\n",
      "Model weights saved in output/checkpoint-2240/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2560\n",
      "Configuration saved in output/checkpoint-2560/config.json\n",
      "Model weights saved in output/checkpoint-2560/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-2880\n",
      "Configuration saved in output/checkpoint-2880/config.json\n",
      "Model weights saved in output/checkpoint-2880/pytorch_model.bin\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: text, image. If text, image are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output/checkpoint-3200\n",
      "Configuration saved in output/checkpoint-3200/config.json\n",
      "Model weights saved in output/checkpoint-3200/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-2880 (score: 0.6734375).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3200, training_loss=0.1545017033815384, metrics={'train_runtime': 131.2019, 'train_samples_per_second': 195.119, 'train_steps_per_second': 24.39, 'total_flos': 848003019571200.0, 'train_loss': 0.1545017033815384, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    output = tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "    # Convert tensors to numpy arrays\n",
    "    return {key: value.numpy() for key, value in output.items()}\n",
    "\n",
    "\n",
    "tokenized_dataset = ocr_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",  # Add this line to set the save_strategy\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,  # Add this line\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d56b4219-fefb-44c8-8b47-6a60a653b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./models/distilbert-base-uncased_model/config.json\n",
      "Model weights saved in ./models/distilbert-base-uncased_model/pytorch_model.bin\n",
      "tokenizer config file saved in ./models/distilbert-base-uncased_tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in ./models/distilbert-base-uncased_tokenizer/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./models/distilbert-base-uncased_tokenizer/tokenizer_config.json',\n",
       " './models/distilbert-base-uncased_tokenizer/special_tokens_map.json',\n",
       " './models/distilbert-base-uncased_tokenizer/vocab.txt',\n",
       " './models/distilbert-base-uncased_tokenizer/added_tokens.json',\n",
       " './models/distilbert-base-uncased_tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./models/distilbert-base-uncased_model\")\n",
    "tokenizer.save_pretrained(\"./models/distilbert-base-uncased_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d73fd0-af8e-4c24-b534-82df58759898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
